\begin{figure*}[!h]
\centering
\begin{minipage}{0.96\textwidth}
% \includegraphics[width=0.95\textwidth]{figures__peekaboo_grid.pdf}
\vspace{-1.0em}
\includegraphics[width=0.95\textwidth]{figures__megagrid.pdf}
\end{minipage}
% \hspace{0.01\textwidth}
\begin{minipage}{0.96\textwidth}
\caption{\textbf{Can diffusion models separate foreground and background?} 
%
Stable diffusion was only trained on RGB images. However, observing the often clean boundaries between objects in generated images, it begs the question: can we use these boundaries to generate images with transparency?
%
In this figure, we conduct a self-contained experiment that answers this question: yes.
%
We overlay 6 learnable foreground images on top of 5 learnable background images using 6 learnable alpha masks, to get a total of 30 learnable composite images. Each of these composite images has a composite caption, created by combining the foreground prompt with the background prompt. For example, the image created by combining background \#1 and foreground \#1 is accompanied by the prompt \texttt{"a bulldozer by a castle"}.
%
We optimize each of these 30 composite cells with score distillation loss (see \cref{subsubsec:sds}) until each foreground, background and alpha mask has been learned.
% 
% 
Differences between this experiment and \modelname are minimal: in Peekaboo, we only optimize the alpha masks, whereas in this analogous experiment we optimize everything.
% 
% foreground and background images are learned whereas in \modelname they are given: foreground is our input image and background is a random RGB color. In \modelname, only the alpha mask is learned.
% % 
%
% example containing synthetic images and segmentation masks generated by a diffusion model. We use this to illustrate how localization information contained within the model can be accessed. The model separately generates 3 elements: foreground, background, and alpha mask. For each cell of the illustrated grid, the alpha mask is used to alpha-blend the foreground and background images, generating the composite image in that cell. For example in cell \texttt{(3, 3)}, foreground \texttt{Darth Vader} is blended using its alpha mask with background \texttt{A fish tank}. The caption of that cell is the combination of foreground and background texts, i.e. in this example \texttt{Darth Vader in a fish tank}. 
% Our dream loss (see \cref{subsec:main_loss}) that enforces cross-modal similarity is applied over the composite image and combined text-caption for each cell. All three elements (foreground, background, alpha mask) are optimized with respect to this loss. The resulting alpha masks converge to good segmentations of the foreground. Note that captions are always used combined and presented separately only for easier illustration.
}
\label{fig:motivation}
\end{minipage}
\vspace{-0.5em}
\end{figure*}

% \begin{figure*}[t]
% \centering
% \begin{minipage}{0.64\textwidth}
% \includegraphics[width=0.95\textwidth]{figures__peekaboo_grid.pdf}
% \end{minipage}
% \hspace{0.01\textwidth}
% \begin{minipage}{0.34\textwidth}
% \caption{\textbf{Can we tap into diffusion models' localization information?} We present a toy example containing synthetic images and segmentation masks generated by a diffusion model. We use this to illustrate how localization information contained within the model can be accessed. The model separately generates 3 elements: foreground, background, and alpha mask. For each cell of the illustrated grid, the alpha mask is used to alpha-blend the foreground and background images, generating the composite image in that cell. For example in cell \texttt{(3, 3)}, foreground \texttt{Darth Vader} is blended using its alpha mask with background \texttt{A fish tank}. The caption of that cell is the combination of foreground and background texts, i.e. in this example \texttt{Darth Vader in a fish tank}. 
% Our dream loss (see \cref{subsec:main_loss}) that enforces cross-modal similarity is applied over the composite image and combined text-caption for each cell. All three elements (foreground, background, alpha mask) are optimized with respect to this loss. The resulting alpha masks converge to good segmentations of the foreground. Note that captions are always used combined and presented separately only for easier illustration.}
% \label{fig:motivation}
% \end{minipage}
% % \vspace{-0.5em}
% \end{figure*}















% \begin{figure*}[t]
% \centering
% \begin{minipage}{0.64\textwidth}
% \includegraphics[width=0.95\textwidth]{figures__megagrid.pdf}
% % \includegraphics[width=0.95\textwidth]{figures__peekaboo_grid.pdf}
% \end{minipage}
% \hspace{0.01\textwidth}
% \begin{minipage}{0.34\textwidth}

% % \caption{\textbf{Can we tap into diffusion models' localization information?} We present a toy example containing synthetic images and segmentation masks generated by a diffusion model. We use this to illustrate how localization information contained within the model can be accessed. The model separately generates 3 elements: foreground, background, and alpha mask. For each cell of the illustrated grid, the alpha mask is used to alpha-blend the foreground and background images, generating the composite image in that cell. For example in cell \texttt{(3, 3)}, foreground \texttt{Darth Vader} is blended using its alpha mask with background \texttt{A fish tank}. The caption of that cell is the combination of foreground and background texts, i.e. in this example \texttt{Darth Vader in a fish tank}. 
% \caption{

% % \todo{

% \textbf{Can diffusion models separate foreground from background?} 
% In this figure we present an experimaent (STILL WRITING BY RYAN)

% We present a toy example containing synthetic images and segmentation masks generated by a diffusion model. We use this to illustrate how localization information contained within the model can be accessed. The model separately generates 3 elements: foreground, background, and alpha mask. For each cell of the illustrated grid, the alpha mask is used to alpha-blend the foreground and background images, generating the composite image in that cell. For example in cell \texttt{(3, 3)}, foreground \texttt{Darth Vader} is blended using its alpha mask with background \texttt{A fish tank}. The caption of that cell is the combination of foreground and background texts, i.e. in this example \texttt{Darth Vader in a fish tank}. 

% Our dream loss (see \cref{subsec:main_loss}) that enforces cross-modal similarity is applied over the composite image and combined text-caption for each cell. All three elements (foreground, background, alpha mask) are optimized with respect to this loss. The resulting alpha masks converge to good segmentations of the foreground. Note that captions are always used combined and presented separately only for easier illustration.}
% \label{fig:motivation}
% \end{minipage}
% % \vspace{-0.5em}
% \end{figure*}