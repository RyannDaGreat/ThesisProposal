
\begin{lstlisting}
#           _  ___  _  _      __ ___  _
#          | \  |  |_ |_ | | (_   |  / \ |\ |
#          |_/ _|_ |  |  |_| __) _|_ \_/ | \|
#          ___            __ ___  _        __
#           |  |  |  | | (_   |  / \ |\ | (_
#          _|_ |_ |_ |_| __) _|_ \_/ | \| __)
#       
#       
#                 _   __  _      _   _
#                |_) (_  |_ | | | \ / \
#                |   __) |_ |_| |_/ \_/
#                     _  _   _   _
#                    /  / \ | \ |_
#                    \_ \_/ |_/ |_


###### PART 1: Initialization
if ILLUSION_TYPE=='FLIP':
    n = 1 #Number of Prime images
    m = 2 #Number of Derived images
    A = [
        #A stands for Arrangements
        lambda P: P[0],
        lambda P: P[0].rot180(),
    ]
    W = [1, 1] # Importance of each derived image
    T = ['Dog', 'Sloth']

if ILLUSION_TYPE=='ROTATE':
    n = 2 #Two Prime Images: Base, Rotator
    m = 4 #Four Derived Images
    k = 2 #The backlight brightness constant
    A = [
        lambda P: k*P[0]*P[1],
        lambda P: k*P[0]*P[1].rot90(),
        lambda P: k*P[0]*P[1].rot180(),
        lambda P: k*P[0]*P[1].rot270(),
    ]
    W = [1, 1, 1, 1]
    T = ['Dog', 'Cat', 'Man', 'Woman']

if ILLUSION_TYPE=='HIDDEN':
    n = 4 #Two Prime Images: A, B, C, D
    m = 5 #Four Derived Images:
          # A, B, C, D, Hidden
    k = 3 #The backlight brightness constant
    A = [
        lambda P: P[0],
        lambda P: P[1],
        lambda P: P[2],
        lambda P: P[3],
        lambda P: k*P[0]*P[1]*P[2]*P[3],
    ]
    W = [1, 1, 1, 1, 3] # Prioritize the hidden image
    T = ['Dog', 'Penguin', 'Giraffe', 'Cow', 'Cat']
    ## OR, to use a QR code or another specific image...
    T = ['Dog', 'Penguin', 'Giraffe', 'Cow',
         load_image('qr_code.png') ]

assert len(T) == len(A) == len(W) == m

# Initialize all prime images
P = [RgbFourierFeatureNetwork(resolution=(512,512))
     for _ in range(n)]

# Initialize our latent diffusion model
F = StableDiffusion()

# We optimize the prime images via gradient descent. 
optim = SGD(P.parameters())


###### PART 2: Helper Functions
def score_distill_loss(image, prompt):
    #Same loss proposed in DreamFusion -
    # but with a latent diffusion model
    image_latent = F.encode_image(image)
    timestep = random_int(0, F.max_timestep)
    noise = F.get_noise(timestep)
    noised_latent = F.add_noise(
        image_latent, noise, timestep
    )    
    with torch.no_grad():
        text_embed = F.clip.embed(prompt)        
        pred_noise = F.unet(
            noised_latent, text_embed, timestep
        )    
    return abs(noise - pred_noise).sum()

def image_similarity(a, b):
    #Our image similarity metric 
    return SSIM(a,b) - MSE(a,b)

def img2img(image, prompt, strength):
    #Based on SDEdit - simplified here
    #When strength=1, the entire image is replaced
    #When strength=0, nothing is changed
    image_latent = F.encode_image(image)
    timestep = int(strength * F.max_timestep)
    noise = F.get_noise(timestep)
    noised_latent = F.add_noise(
        image_latent, noise, timestep
    )

    #Perform diffusion as normal, but starting from
    #our noised_latent instead of pure noise
    diffused_latent = F.text_to_image(
        prompt,
        initial_latent=noised_latent,
        initial_timestep=timestep,
    )

    new_image = F.decode_image(diffused_latent)
    return new_image


###### PART 3: Optimization

#Phase 1: Score Distillation Loss

for iteration in range(10000):
    loss = 0
    for a,t,w in zip(A,T,W):
        # Derived image d
        # comes from an arrangement of prime images
        d = a(P)
        if isinstance(t, str):
            loss += w * score_distill_loss(d, t)
        elif is_image(t):
            # For hiding custom images such as QR codes
            loss -= w * image_similarity(d, t)
    optim.update(loss) # Take a gradient descent step

#Phase 2: Dream-Target Loss

#Start from strength = .90 instead of 1
# in order to use the results from Phase 1
schedule = [.90, .89, .88 ... .03, .02, .01]

for strength in schedule:
    # Define the image translation function
    G = lambda text,image: img2img(text,image,strength)

    # Step 1: Set our Dream-Targets
    Z = []
    for a, t in zip(A,T):
        if isinstance(t, str):
            # Tweak a derived image to get a new target
            d = a(P)
            z = G(t, d)
        elif is_image(t):
            #Use a predefined target (e.g. a QR code)
            z = t
        Z.append(z)

    # Step 2: Approach our Dream-Targets
    for iteration in range(1000):
        #Optimize P so that D approaches T

        loss = 0
        for a,z,w in zip(A,Z,W):
            d = a(P)
            loss -= w * image_similarity(d, z)
            
        # Take a gradient descent step
        optim.update(loss)

        
###### PART 4: Fabrication
        
#We're done! Return the primes - 
# and print them out physically! 
printed_P = send_to_laser_printer(P)

#Oh, and also, make sure someone uses them...
fun = have_human_arrange_the_illusions(printed_P)
\end{lstlisting}

