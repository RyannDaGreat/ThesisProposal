@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP= {ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL = {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  = {BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   = {IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  = {ICME})
@String(ICASSP= {ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


@misc{motioneditor,
      title={MotionEditor: Editing Video Motion via Content-Aware Diffusion}, 
      author={Shuyuan Tu and Qi Dai and Zhi-Qi Cheng and Han Hu and Xintong Han and Zuxuan Wu and Yu-Gang Jiang},
      year={2023},
      eprint={2311.18830},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

% REMOVED DUPLICATE - using i2vedit2024 instead

@misc{ati,
      title={ATI: Any Trajectory Instruction for Controllable Video Generation}, 
      author={Angtian Wang and Haibin Huang and Jacob Zhiyuan Fang and Yiding Yang and Chongyang Ma},
      year={2025},
      eprint={2505.22944},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{videodirectorgpt,
      title={VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided Planning}, 
      author={Han Lin and Abhay Zala and Jaemin Cho and Mohit Bansal},
      year={2024},
      eprint={2309.15091},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{motionclone,
      title={MotionClone: Training-Free Motion Cloning for Controllable Video Generation}, 
      author={Pengyang Ling and Jiazi Bu and Pan Zhang and Xiaoyi Dong and Yuhang Zang and Tong Wu and Huaian Chen and Jiaqi Wang and Yi Jin},
      year={2024},
      eprint={2406.05338},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{zhang2024monst3r,
  title={Monst3r: A simple approach for estimating geometry in the presence of motion},
  author={Zhang, Junyi and Herrmann, Charles and Hur, Junhwa and Jampani, Varun and Darrell, Trevor and Cole, Forrester and Sun, Deqing and Yang, Ming-Hsuan},
  journal={arXiv preprint arXiv:2410.03825},
  year={2024}
}
@misc{lpips,
      title={The Unreasonable Effectiveness of Deep Features as a Perceptual Metric}, 
      author={Richard Zhang and Phillip Isola and Alexei A. Efros and Eli Shechtman and Oliver Wang},
      year={2018},
      eprint={1801.03924},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{fid,
      title={GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium}, 
      author={Martin Heusel and Hubert Ramsauer and Thomas Unterthiner and Bernhard Nessler and Sepp Hochreiter},
      year={2018},
      eprint={1706.08500},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

% REMOVED DUPLICATE - using controlnet2023 instead

% REMOVED DUPLICATE - using revideo2024 instead

% REMOVED DUPLICATE - using gowiththeflow2025 instead

% REMOVED DUPLICATE - using motionprompt2024 instead

@misc{motionfollower,
      title={MotionFollower: Editing Video Motion via Lightweight Score-Guided Diffusion}, 
      author={Shuyuan Tu and Qi Dai and Zihao Zhang and Sicheng Xie and Zhi-Qi Cheng and Chong Luo and Xintong Han and Zuxuan Wu and Yu-Gang Jiang},
      year={2024},
      eprint={2405.20325},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2405.20325}, 
}


@misc{wan,
      title={Wan: Open and Advanced Large-Scale Video Generative Models}, 
      author={Team Wan and Ang Wang and Baole Ai and Bin Wen and Chaojie Mao and Chen-Wei Xie and Di Chen and Feiwu Yu and Haiming Zhao and Jianxiao Yang and Jianyuan Zeng and Jiayu Wang and Jingfeng Zhang and Jingren Zhou and Jinkai Wang and Jixuan Chen and Kai Zhu and Kang Zhao and Keyu Yan and Lianghua Huang and Mengyang Feng and Ningyi Zhang and Pandeng Li and Pingyu Wu and Ruihang Chu and Ruili Feng and Shiwei Zhang and Siyang Sun and Tao Fang and Tianxing Wang and Tianyi Gui and Tingyu Weng and Tong Shen and Wei Lin and Wei Wang and Wei Wang and Wenmeng Zhou and Wente Wang and Wenting Shen and Wenyuan Yu and Xianzhong Shi and Xiaoming Huang and Xin Xu and Yan Kou and Yangyu Lv and Yifei Li and Yijing Liu and Yiming Wang and Yingya Zhang and Yitong Huang and Yong Li and You Wu and Yu Liu and Yulin Pan and Yun Zheng and Yuntao Hong and Yupeng Shi and Yutong Feng and Zeyinzi Jiang and Zhen Han and Zhi-Fan Wu and Ziyu Liu},
      year={2025},
      eprint={2503.20314},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2503.20314}, 
}

% REMOVED DUPLICATE - using cogvideox2024 instead
@misc{tapnext,
      title={TAPNext: Tracking Any Point (TAP) as Next Token Prediction},
      author={Artem Zholus and Carl Doersch and Yi Yang and Skanda Koppula and Viorica Patraucean and Xu Owen He and Ignacio Rocco and Mehdi S. M. Sajjadi and Sarath Chandar and Ross Goroshin},
      year={2025},
      eprint={2504.05579},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2504.05579}
}

% REMOVED DUPLICATE - using das2025 instead

@inproceedings{davis2016,
  author = {F. Perazzi and J. Pont-Tuset and B. McWilliams and L. {Van Gool} and M. Gross and A. Sorkine-Hornung},
  title = {A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation},
  booktitle = CVPR,
  year = {2016}
}

% ============================================
% ADDED CITATIONS FOR COMPREHENSIVE RELATED WORKS
% Generated 2025-11-12
% ============================================

% FOUNDATIONAL DIFFUSION
@inproceedings{ddpm2020,
      title={Denoising Diffusion Probabilistic Models},
      author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
      booktitle=NIPS,
      year={2020}
}

@inproceedings{stablediffusion2022,
      title={High-Resolution Image Synthesis with Latent Diffusion Models},
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Bj{\"o}rn Ommer},
      booktitle=CVPR,
      year={2022}
}

@inproceedings{controlnet2023,
      title={Adding Conditional Control to Text-to-Image Diffusion Models},
      author={Lvmin Zhang and Anyi Rao and Maneesh Agrawala},
      booktitle=ICCV,
      year={2023}
}

@inproceedings{dit2023,
      title={Scalable Diffusion Models with Transformers},
      author={William Peebles and Saining Xie},
      booktitle=ICCV,
      year={2023}
}

% DRAG-BASED METHODS
@inproceedings{draggan2023,
      title={Drag Your {GAN}: Interactive Point-based Manipulation on the Generative Image Manifold},
      author={Xingang Pan and Ayush Tewari and Thomas Leimk{\"u}hler and Lingjie Liu and Abhimitra Meka and Christian Theobalt},
      booktitle={SIGGRAPH},
      year={2023}
}

@inproceedings{dragdiffusion2024,
      title={{DragDiffusion}: Harnessing Diffusion Models for Interactive Point-based Image Editing},
      author={Yujun Shi and Chuhui Xue and Jiachun Pan and Wenqing Zhang and Vincent Y. F. Tan and Song Bai},
      booktitle=CVPR,
      year={2024}
}

@inproceedings{dragondiffusion2024,
      title={{DragonDiffusion}: Enabling Drag-style Manipulation on Diffusion Models},
      author={Chong Mou and Xintao Wang and Jiechong Song and Ying Shan and Jian Zhang},
      booktitle=ICLR,
      year={2024}
}

@inproceedings{freedrag2024,
      title={{FreeDrag}: Point Tracking is Not You Need for Interactive Point-based Image Editing},
      author={Pengyang Ling and Lin Chen and Pan Zhang and Huaian Chen and Yi Jin},
      booktitle=CVPR,
      year={2024}
}

@inproceedings{stabledrag2024,
      title={{StableDrag}: Stable Dragging for Point-based Image Editing},
      author={Yutao Cui and Xiaotong Zhao and Guozhen Zhang and Shengming Cao and Kai Ma and Limin Wang},
      booktitle=ECCV,
      year={2024}
}

@misc{draganything2024,
      title={{DragAnything}: Motion Control for Anything using Entity Representation},
      author={Weijia Wu and Zhuang Li and Yuchao Gu and Rui Zhao and Yefei He and David Junhao Zhang and Mike Zheng Shou and Yan Li and Tingting Gao and Di Zhang},
      year={2024},
      eprint={2403.07420},
      archivePrefix={arXiv}
}

@misc{dragavideo2023,
      title={Drag-A-Video: Non-rigid Video Editing with Point-based Interaction},
      author={Yao Teng and Enze Xie and Yue Wu and Haoyu Han and Zhenguo Li and Xihui Liu},
      year={2023},
      eprint={2312.02936},
      archivePrefix={arXiv}
}

@misc{dragnuwa2023,
      title={{DragNUWA}: Fine-grained Control in Video Generation by Integrating Text, Image, and Trajectory},
      author={Shengming Yin and Chenfei Wu and Jian Liang and Jie Shi and Houqiang Li and Gong Ming and Nan Duan},
      year={2023},
      eprint={2308.08089},
      archivePrefix={arXiv}
}

@inproceedings{dragvideo2024,
      title={{DragVideo}: Interactive Drag-style Video Editing},
      author={Authors},
      booktitle=ECCV,
      year={2024}
}

% VIDEO DIFFUSION FOUNDATIONAL
@inproceedings{vdm2022,
      title={Video Diffusion Models},
      author={Jonathan Ho and Tim Salimans and Alexey Gritsenko and William Chan and Mohammad Norouzi and David J. Fleet},
      booktitle=NIPS,
      year={2022}
}

@misc{imagenvideo2022,
      title={Imagen Video: High Definition Video Generation with Diffusion Models},
      author={Jonathan Ho and William Chan and Chitwan Saharia and Jay Whang and Ruiqi Gao and Alexey Gritsenko and Diederik P. Kingma and Ben Poole and Mohammad Norouzi and David J. Fleet and Tim Salimans},
      year={2022},
      eprint={2210.02303},
      archivePrefix={arXiv}
}

@inproceedings{bar2024lumiere,
  title={Lumiere: A space-time diffusion model for video generation},
  author={Bar-Tal, Omer and Chefer, Hila and Tov, Omer and Herrmann, Charles and Paiss, Roni and Zada, Shiran and Ephrat, Ariel and Hur, Junhwa and Liu, Guanghui and Raj, Amit and others},
  booktitle={SIGGRAPH Asia 2024 Conference Papers},
  pages={1--11},
  year={2024}
}

@misc{makeavideo2022,
      title={Make-A-Video: Text-to-Video Generation without Text-Video Data},
      author={Uriel Singer and Adam Polyak and Thomas Hayes and Xi Yin and Jie An and Songyang Zhang and Qiyuan Hu and Harry Yang and Oron Ashual and Oran Gafni and Devi Parikh and Sonal Gupta and Yaniv Taigman},
      year={2022},
      eprint={2209.14792},
      archivePrefix={arXiv}
}

@misc{cogvideox2024,
      title={{CogVideoX}: Text-to-Video Diffusion Models with An Expert Transformer},
      author={Zhuoyi Yang and Jiayan Teng and Wendi Zheng and Ming Ding and Shiyu Huang and Jiazheng Xu and Yuanming Yang and Wenyi Hong and Xiaohan Zhang and Guanyu Feng and Da Yin and Xiaotao Gu and Yuxuan Zhang and Weihan Wang and Yean Cheng and Xu Bin and Yuxiao Dong and Jie Tang},
      year={2024},
      eprint={2408.06072},
      archivePrefix={arXiv}
}

@misc{svd2023,
      title={Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets},
      author={Andreas Blattmann and Tim Dockhorn and Sumith Kulal and Daniel Mendelevitch and Maciej Kilian and Dominik Lorenz and Yam Levi and Zion English and Vikram Voleti and Adam Letts and Varun Jampani and Robin Rombach},
      year={2023},
      eprint={2311.15127},
      archivePrefix={arXiv}
}

@misc{animatediff2023,
      title={{AnimateDiff}: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning},
      author={Yuwei Guo and Ceyuan Yang and Anyi Rao and Zhengyang Liang and Yaohui Wang and Yu Qiao and Maneesh Agrawala and Dahua Lin and Bo Dai},
      year={2023},
      eprint={2307.04725},
      archivePrefix={arXiv}
}

@misc{dynamicrafter2024,
      title={{DynamiCrafter}: Animating Open-domain Images with Video Diffusion Priors},
      author={Jinbo Xing and Menghan Xia and Yong Zhang and Haoxin Chen and Wangbo Yu and Hanyuan Liu and Gongye Liu and Xintao Wang and Ying Shan and Tien-Tsin Wong},
      year={2024},
      eprint={2310.12190},
      archivePrefix={arXiv}
}

@misc{i2vgenxl2023,
      title={{I2VGen-XL}: High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models},
      author={Shiwei Zhang and Jiayu Wang and Yingya Zhang and Kang Zhao and Hangjie Yuan and Zhiwu Qing and Xiang Wang and Deli Zhao and Jingren Zhou},
      year={2023},
      eprint={2311.04145},
      archivePrefix={arXiv}
}

@article{latte2024,
      title={Latte: Latent Diffusion Transformer for Video Generation},
      author={Xin Ma and Yaohui Wang and Gengyun Jia and Xinyuan Chen and Ziwei Liu and Yuan-Fang Li and Cunjian Chen and Yu Qiao},
      journal={TMLR},
      year={2025}
}

@misc{opensora2024,
      title={Open-Sora: Democratizing Efficient Video Production for All},
      author={Zangwei Zheng and Xiangyu Peng and Tianji Yang and Chenhui Shen and Shenggui Li and Hongxin Liu and Yukun Zhou and Tianyi Li and Yang You},
      year={2024},
      eprint={2412.20404},
      archivePrefix={arXiv}
}

% CONDITIONAL VIDEO DIFFUSION
@misc{das2025,
      title={Diffusion as Shader: {3D}-aware Video Diffusion for Versatile Video Generation Control},
      author={Zekai Gu and Rui Yan and Jiahao Lu and Peng Li and Zhiyang Dou and Chenyang Si and Zhen Dong and Qifeng Liu and Cheng Lin and Ziwei Liu and Wenping Wang and Yuan Liu},
      year={2025},
      eprint={2501.03847},
      archivePrefix={arXiv}
}

@misc{videocontrolnet2023,
      title={{VideoControlNet}: A Motion-Guided Video-to-Video Translation Framework},
      author={Zhihao Hu and Dong Xu},
      year={2023},
      eprint={2307.14073},
      archivePrefix={arXiv}
}

@misc{motioni2v2024,
      title={Motion-{I2V}: Consistent and Controllable Image-to-Video Generation with Explicit Motion Modeling},
      author={Xiaoyu Shi and Zhaoyang Huang and Fu-Yun Wang and Weikang Bian and Dasong Li and Yi Zhang and Manyuan Zhang and Ka Chun Cheung and Simon See and Hongwei Qin and Jifeng Dai and Qifeng Chen},
      year={2024},
      eprint={2401.15977},
      archivePrefix={arXiv}
}

% VIDEO EDITING - TEMPORAL CONSISTENCY
@inproceedings{tokenflow2024,
      title={{TokenFlow}: Consistent Diffusion Features for Consistent Video Editing},
      author={Michal Geyer and Omer Bar-Tal and Shai Bagon and Tali Dekel},
      booktitle=ICLR,
      year={2024}
}

@inproceedings{fatezero2023,
      title={{FateZero}: Fusing Attentions for Zero-shot Text-based Video Editing},
      author={Chenyang Qi and Xiaodong Cun and Yong Zhang and Chenyang Lei and Xintao Wang and Ying Shan and Qifeng Chen},
      booktitle=ICCV,
      year={2023}
}

@inproceedings{codef2024,
      title={{CoDeF}: Content Deformation Fields for Temporally Consistent Video Processing},
      author={Hao Ouyang and Qiuyu Wang and Yuxi Xiao and Qingyan Bai and Juntao Zhang and Kecheng Zheng and Xiaowei Zhou and Qifeng Chen and Yujun Shen},
      booktitle=CVPR,
      year={2024}
}

@inproceedings{pix2video2023,
      title={{Pix2Video}: Video Editing using Image Diffusion},
      author={Duygu Ceylan and Chun-Hao Paul Huang and Niloy J. Mitra},
      booktitle=ICCV,
      year={2023}
}

@inproceedings{vidtome2024,
      title={{VidToMe}: Video Token Merging for Zero-Shot Video Editing},
      author={Xirui Li and Chao Ma and Xiaokang Yang and Ming-Hsuan Yang},
      booktitle=CVPR,
      year={2024}
}

@inproceedings{rave2024,
      title={{RAVE}: Randomized Noise Shuffling for Fast and Consistent Video Editing},
      author={Ozgur Kara and Bariscan Kurtkaya and Hidir Yesiltepe and James M. Rehg and Pinar Yanardag},
      booktitle=CVPR,
      year={2024}
}

@inproceedings{tuneavideo2023,
      title={Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation},
      author={Jay Zhangjie Wu and Yixiao Ge and Xintao Wang and Stan Weixian Lei and Yuchao Gu and Yufei Shi and Wynne Hsu and Ying Shan and Xiaohu Qie and Mike Zheng Shou},
      booktitle=ICCV,
      year={2023}
}

@inproceedings{text2videozero2023,
      title={{Text2Video-Zero}: Text-to-Image Diffusion Models are Zero-Shot Video Generators},
      author={Levon Khachatryan and Andranik Movsisyan and Vahram Tadevosyan and Roberto Henschel and Zhangyang Wang and Shant Navasardyan and Humphrey Shi},
      booktitle=ICCV,
      year={2023}
}

@inproceedings{cove2024,
      title={{COVE}: Unleashing the Diffusion Feature Correspondence for Consistent Video Editing},
      author={Jiangshan Wang and Yue Ma and Jiayi Guo and Yicheng Xiao and Gao Huang and Xiu Li},
      booktitle=NIPS,
      year={2024}
}

@misc{i2vedit2024,
      title={{I2VEdit}: First-Frame-Guided Video Editing via Image-to-Video Diffusion Models},
      author={Wenqi Ouyang and Yi Dong and Lei Yang and Jianlou Si and Xingang Pan},
      year={2024},
      eprint={2405.16537},
      archivePrefix={arXiv}
}

@misc{magicedit2023,
      title={{MagicEdit}: High-Fidelity and Temporally Coherent Video Editing},
      author={Jun Hao Liew and Hanshu Yan and Jianfeng Zhang and Zhongcong Xu and Jiashi Feng},
      year={2023},
      eprint={2308.14749},
      archivePrefix={arXiv}
}

@inproceedings{stablevideo2023,
      title={{StableVideo}: Text-driven Consistency-aware Diffusion Video Editing},
      author={Wenhao Chai and Xun Guo and Gaoang Wang and Yan Lu},
      booktitle=ICCV,
      year={2023}
}

% MOTION-CONTROLLED VIDEO GENERATION
@misc{motionprompt2024,
      title={Motion Prompting: Controlling Video Generation with Motion Trajectories},
      author={Daniel Geng and Charles Herrmann and Junhwa Hur and Forrester Cole and Serena Zhang and Tobias Pfaff and Tatiana Lopez-Guevara and Carl Doersch and Yusuf Aytar and Michael Rubinstein and Chen Sun and Oliver Wang and Andrew Owens and Deqing Sun},
      year={2024},
      eprint={2412.02700},
      archivePrefix={arXiv}
}

@misc{gowiththeflow2025,
      title={Go-with-the-Flow: Motion-Controllable Video Diffusion Models Using Real-Time Warped Noise},
      author={Ryan Burgert and Yuancheng Xu and Wenqi Xian and Oliver Pilarski and Pascal Clausen and Mingming He and Li Ma and Yitong Deng and Lingxiao Li and Mohsen Mousavi and Michael Ryoo and Paul Debevec and Ning Yu},
      year={2025},
      eprint={2501.08331},
      archivePrefix={arXiv}
}

% REMOVED trackr2v2026 as per user request

@misc{revideo2024,
      title={{ReVideo}: Remake a Video with Motion and Content Control},
      author={Chong Mou and Mingdeng Cao and Xintao Wang and Zhaoyang Zhang and Ying Shan and Jian Zhang},
      year={2024},
      eprint={2405.13865},
      archivePrefix={arXiv}
}

@misc{tora2024,
      title={Tora: Trajectory-oriented Diffusion Transformer for Video Generation},
      author={Zhenghao Zhang and Junchao Liao and Menghao Li and Long Qin and Weizhi Wang},
      year={2024},
      eprint={2407.21705},
      archivePrefix={arXiv}
}

@misc{imageconductor2024,
      title={Image Conductor: Precision Control for Interactive Video Synthesis},
      author={Yaowei Li and Xintao Wang and Zhaoyang Zhang and Zhouxia Wang and Ziyang Yuan and Liangbin Xie and Yuexian Zou and Ying Shan},
      year={2024},
      eprint={2406.15339},
      archivePrefix={arXiv}
}

@inproceedings{boximator2024,
      title={Boximator: Generating Rich and Controllable Motions for Video Synthesis},
      author={Jiawei Wang and Yuchen Zhang and Jiaxin Zou and Yan Zeng and Guoqiang Wei and Liping Yuan and Hang Li},
      booktitle={ICML},
      year={2024}
}

@misc{i2vcontrol2024,
      title={{I2VControl}: Disentangled and Unified Video Motion Synthesis Control},
      author={Wanquan Feng and Tianhao Qi and Jiawei Liu and Mingzhen Sun and Pengqi Tu and Tianxiang Ma and Fei Dai and Songtao Zhao and Siyu Zhou and Qian He},
      year={2024},
      eprint={2411.17765},
      archivePrefix={arXiv}
}

@misc{3dtrajmaster2024,
      title={{3DTrajMaster}: Mastering {3D} Trajectory for Multi-Entity Motion in Video Generation},
      author={Xiao Fu and Xian Liu and Xintao Wang and Sida Peng and Menghan Xia and Xiaoyu Shi and Ziyang Yuan and Pengfei Wan and Di Zhang and Dahua Lin},
      year={2024},
      eprint={2412.07759},
      archivePrefix={arXiv}
}

@misc{flextraj2024,
      title={{FlexTraj}: Image-to-Video Generation with Flexible Point Trajectory Control},
      author={Zhiyuan Zhang and Can Wang and Dongdong Chen and Jing Liao},
      year={2024},
      eprint={2510.08527},
      archivePrefix={arXiv}
}

@misc{freetraj2024,
      title={{FreeTraj}: Tuning-Free Trajectory Control in Video Diffusion Models},
      author={Haonan Qiu and Zhaoxi Chen and Zhouxia Wang and Yingqing He and Menghan Xia and Ziwei Liu},
      year={2024},
      eprint={2406.16863},
      archivePrefix={arXiv}
}

@misc{trailblazer2024,
      title={{TrailBlazer}: Trajectory Control for Diffusion-Based Video Generation},
      author={Wan-Duo Kurt Ma and John P. Lewis and W. Bastiaan Kleijn},
      year={2024},
      eprint={2401.00896},
      archivePrefix={arXiv}
}

@misc{onlyflow2024,
      title={{OnlyFlow}: Optical Flow based Motion Conditioning for Video Diffusion Models},
      author={Mathis Koroglu and Hugo Caselles-Dupr{\'e} and Guillaume Jeanneret and Matthieu Cord},
      year={2024},
      eprint={2411.10501},
      archivePrefix={arXiv}
}

@misc{animateanything2024,
      title={{AnimateAnything}: Consistent and Controllable Animation for Video Generation},
      author={Guojun Lei and Chi Wang and Hong Li and Rong Zhang and Yikai Wang and Weiwei Xu},
      year={2024},
      eprint={2411.10836},
      archivePrefix={arXiv}
}

% CAMERA CONTROL
@misc{cameractrl2024,
      title={{CameraCtrl}: Enabling Camera Control for Text-to-Video Generation},
      author={Hao He and Yinghao Xu and Yuwei Guo and Gordon Wetzstein and Bo Dai and Hongsheng Li and Ceyuan Yang},
      year={2024},
      eprint={2404.02101},
      archivePrefix={arXiv}
}

@misc{ac3d2024,
      title={{AC3D}: Analyzing and Improving {3D} Camera Control in Video Diffusion Transformers},
      author={Sherwin Bahmani and Ivan Skorokhodov and Guocheng Qian and Aliaksandr Siarohin and Willi Menapace and Andrea Tagliasacchi and David B. Lindell and Sergey Tulyakov},
      year={2024},
      eprint={2411.18673},
      archivePrefix={arXiv}
}

@misc{vd3d2024,
      title={{VD3D}: Taming Large Video Diffusion Transformers for {3D} Camera Control},
      author={Sherwin Bahmani and Ivan Skorokhodov and Aliaksandr Siarohin and Willi Menapace and Guocheng Qian and Michael Vasilkovsky and Hsin-Ying Lee and Chaoyang Wang and Jiaxu Zou and Andrea Tagliasacchi and David B. Lindell and Sergey Tulyakov},
      year={2024},
      eprint={2407.12781},
      archivePrefix={arXiv}
}

@misc{motionctrl2023,
      title={{MotionCtrl}: A Unified and Flexible Motion Controller for Video Generation},
      author={Zhouxia Wang and Ziyang Yuan and Xintao Wang and Yaowei Li and Tianshui Chen and Menghan Xia and Ping Luo and Ying Shan},
      year={2023},
      eprint={2312.03641},
      archivePrefix={arXiv}
}

@misc{directavideo2024,
      title={Direct-a-Video: Customized Video Generation with User-Directed Camera Movement and Object Motion},
      author={Shiyuan Yang and Liang Hou and Haibin Huang and Chongyang Ma and Pengfei Wan and Di Zhang and Xiaodong Chen and Jing Liao},
      year={2024},
      eprint={2402.03162},
      archivePrefix={arXiv}
}

@misc{viewcrafter2024,
      title={{ViewCrafter}: Taming Video Diffusion Models for High-fidelity Novel View Synthesis},
      author={Wangbo Yu and Jinbo Xing and Li Yuan and Wenbo Hu and Xiaoyu Li and Zhipeng Huang and Xiangjun Gao and Tien-Tsin Wong and Ying Shan and Yonghong Tian},
      year={2024},
      eprint={2409.02048},
      archivePrefix={arXiv}
}

@misc{recammaster2025,
      title={{ReCamMaster}: Camera-Controlled Generative Rendering from A Single Video},
      author={Jianhong Bai and Menghan Xia and Xintao Wang and Ziyang Yuan and Xiao Fu and Zuozhu Liu and Haoji Hu and Pengfei Wan and Di Zhang},
      year={2025},
      eprint={2503.11647},
      archivePrefix={arXiv}
}

@misc{trajectorycrafter2025,
      title={{TrajectoryCrafter}: Redirecting Camera Trajectory for Monocular Videos},
      author={Yicheng Wang and Zheyuan Liu and Yifei Yue and Jiawei Li and Jianhong Bai and Chao Ma and Jianfeng Wang and Ziyang Yuan and Zuozhu Liu and Di Zhang and Haoji Hu and Xintao Wang},
      year={2025},
      eprint={2503.05638},
      archivePrefix={arXiv}
}

@misc{recapture2024,
      title={{ReCapture}: Generative Video Camera Controls for User-Provided Videos},
      author={David Junhao Zhang and Roni Paiss and Shiran Zada and Nikhil Karnad and David E. Jacobs and Yael Pritch and Inbar Mosseri and Neal Wadhwa and Nataniel Ruiz and Mike Zheng Shou and Sagie Benaim and Yijun Li and Kfir Aberman},
      year={2024},
      eprint={2411.05003},
      archivePrefix={arXiv}
}

@misc{gen3c2025,
      title={{GEN3C}: {3D}-Informed World-Consistent Video Generation with Precise Camera Control},
      author={Xuanchi Ren and Tianchang Shen and Jiahui Huang and Huan Ling and Yifan Lu and Merlin Nimier-David and Thomas M{\"u}ller and Alexander Keller and Sanja Fidler and Jun Gao},
      year={2025},
      note={NVIDIA, CVPR 2025 Highlight}
}

@misc{cavia2024,
      title={Cavia: Camera-controllable Multi-view Video Diffusion},
      author={Qi Zuo and Xiaodong Gu and Lingteng Qiu and Yuan Dong and Zhengyi Zhao and Weihao Yuan and Rui Peng and Siyu Zhu and Zilong Dong and Liefeng Bo and Qixing Huang},
      year={2024},
      eprint={2410.10774},
      archivePrefix={arXiv}
}

@misc{camco2024,
      title={{CamCo}: Camera-Controllable {3D}-Consistent Image-to-Video Generation},
      author={Dejia Xu and Weili Nie and Chao Liu and Sifei Liu and Jan Kautz and Zhangyang Wang and Arash Vahdat},
      year={2024},
      eprint={2406.02509},
      archivePrefix={arXiv}
}

% 3D-AWARE GENERATION
@misc{shapeformotion2025,
      title={Shape-for-Motion: Precise and Consistent Video Editing With {3D} Proxy},
      author={Yuhao Liu and Tengfei Wang and Fang Liu and Zhenwei Wang and Rynson W. H. Lau},
      year={2025},
      eprint={2506.22432},
      archivePrefix={arXiv}
}

@misc{worldconsistent2024,
      title={World-consistent Video Diffusion with Explicit {3D} Modeling},
      author={Qihang Zhang and Shuangfei Zhai and Miguel Angel Bautista and Kevin Miao and Alexander Toshev and Joshua Susskind and Jiatao Gu},
      year={2024},
      eprint={2412.01821},
      archivePrefix={arXiv}
}

@inproceedings{genrendering2024,
      title={Generative Rendering: Controllable {4D}-Guided Video Generation with {2D} Diffusion Models},
      author={Shengqu Cai and Duygu Ceylan and Matheus Gadelha and Chun-Hao Paul Huang and Tuanfeng Yang Wang and Gordon Wetzstein},
      booktitle=CVPR,
      year={2024}
}

@inproceedings{4dgs2024,
      title={{4D} Gaussian Splatting for Real-Time Dynamic Scene Rendering},
      author={Guanjun Wu and Taoran Yi and Jiemin Fang and Lingxi Xie and Xiaopeng Zhang and Wei Wei and Wenyu Liu and Qi Tian and Xinggang Wang},
      booktitle=CVPR,
      year={2024}
}

@inproceedings{sv3d2024,
      title={{SV3D}: Novel Multi-view Synthesis and {3D} Generation from a Single Image},
      author={Vikram Voleti and Chun-Han Yao and Mark Boss and Adam Letts and David Pankratz and Dmitrii Tochilkin and Christian Laforte and Robin Rombach and Varun Jampani},
      booktitle=ECCV,
      year={2024}
}

@misc{sv4d2024,
      title={{SV4D}: Dynamic {3D} Content Generation with Multi-Frame and Multi-View Consistency},
      author={Yiming Xie and Chun-Han Yao and Vikram Voleti and Huaizu Jiang and Varun Jampani},
      year={2024},
      eprint={2407.17470},
      archivePrefix={arXiv}
}

@misc{sketch3dve2024,
      title={{Sketch3DVE}: Sketch-based {3D}-Aware Scene Video Editing},
      author={Feng-Lin Liu and Shi-Yang Li and Yan-Pei Cao and Hongbo Fu and Lin Gao},
      year={2024},
      eprint={2508.13797},
      archivePrefix={arXiv}
}

@misc{diffusion4d2024,
      title={{Diffusion4D}: Fast Spatial-temporal Consistent {4D} Generation},
      author={Hanwen Liang and Yuyang Yin and Dejia Xu and Hanxue Liang and Zhangyang Wang and Konstantinos N. Plataniotis and Yao Zhao and Yunchao Wei},
      year={2024},
      eprint={2405.16645},
      archivePrefix={arXiv}
}

@inproceedings{motiongs2024,
      title={{MotionGS}: Exploring Explicit Motion Guidance for Deformable {3D} Gaussian Splatting},
      author={Ruijie Zhu and Yanzhe Liang and Hanzhi Chang and Jiacheng Deng and Jiahao Lu and Wenfei Yang and Tianzhu Zhang and Yongdong Zhang},
      booktitle=NIPS,
      year={2024}
}

% POINT TRACKING
@inproceedings{tapir2023,
      title={{TAPIR}: Tracking Any Point with Per-Frame Initialization and Temporal Refinement},
      author={Carl Doersch and Yi Yang and Mel Vecerik and Dilara Gokay and Ankush Gupta and Yusuf Aytar and Joao Carreira and Andrew Zisserman},
      booktitle=ICCV,
      year={2023}
}

@misc{bootstap2024,
      title={{BootsTAP}: Bootstrapped Training for Tracking-Any-Point},
      author={Carl Doersch and Pauline Luc and Yi Yang and Dilara Gokay and Skanda Koppula and Ankush Gupta and Joseph Heyward and Ignacio Rocco and Ross Goroshin and Joao Carreira and Andrew Zisserman},
      year={2024},
      eprint={2402.00847},
      archivePrefix={arXiv}
}

@misc{cotracker3_2024,
      title={{CoTracker3}: Simpler and Better Point Tracking by Pseudo-Labelling Real Videos},
      author={Nikita Karaev and Iurii Makarov and Jianyuan Wang and Natalia Neverova and Andrea Vedaldi and Christian Rupprecht},
      year={2024},
      eprint={2410.11831},
      archivePrefix={arXiv}
}

@inproceedings{spatialtracker2024,
      title={{SpatialTracker}: Tracking Any {2D} Pixels in {3D} Space},
      author={Yuxi Xiao and Qianqian Wang and Shangzhan Zhang and Nan Xue and Sida Peng and Yujun Shen and Xiaowei Zhou},
      booktitle=CVPR,
      year={2024}
}

@inproceedings{locotrack2024,
      title={{LocoTrack}: Local All-Pair Correspondence for Point Tracking},
      author={Seong Hyeon Park and Roni Paiss and Rika Goya and Hiromasa Yoshimoto and Humphrey Shi and Joon-Young Lee and Kfir Aberman and Zhixun Su},
      booktitle=ECCV,
      year={2024}
}

@misc{delta2024,
      title={{DELTA}: Dense Efficient Long-range {3D} Tracking for Any Video},
      author={Tuan Duc Ngo and Peiye Zhuang and Chuang Gan and Evangelos Kalogerakis and Sergey Tulyakov and Hsin-Ying Lee and Chaoyang Wang},
      year={2024},
      eprint={2410.24211},
      archivePrefix={arXiv}
}

@inproceedings{omnimotion2023,
      title={Tracking Everything Everywhere All at Once},
      author={Qianqian Wang and Yen-Yu Chang and Ruojin Cai and Zhengqi Li and Bharath Hariharan and Aleksander Holynski and Noah Snavely},
      booktitle=ICCV,
      year={2023}
}

@inproceedings{pips2022,
      title={Particle Video Revisited: Tracking Through Occlusions Using Point Trajectories},
      author={Adam W. Harley and Zhaoyuan Fang and Katerina Fragkiadaki},
      booktitle=ECCV,
      year={2022}
}

@inproceedings{raft2020,
      title={{RAFT}: Recurrent All-Pairs Field Transforms for Optical Flow},
      author={Zachary Teed and Jia Deng},
      booktitle=ECCV,
      year={2020}
}

% VIDEO EDITING ADDITIONAL
@misc{ccedit2024,
      title={{CCEdit}: Creative and Controllable Video Editing via Diffusion Models},
      author={Ruoyu Feng and Wenming Weng and Yanhui Wang and Yuhui Yuan and Jianmin Bao and Chong Luo and Zhibo Chen and Baining Guo},
      year={2024},
      eprint={2309.16496},
      archivePrefix={arXiv}
}

@inproceedings{videocomposer2023,
      title={{VideoComposer}: Compositional Video Synthesis with Motion Controllability},
      author={Xiang Wang and Hangjie Yuan and Shiwei Zhang and Dayou Chen and Jiuniu Wang and Yingya Zhang and Yujun Shen and Deli Zhao and Jingren Zhou},
      booktitle=NIPS,
      year={2023}
}

@inproceedings{mofavideo2024,
      title={{MOFA-Video}: Controllable Image Animation via Motion Field Adaptions},
      author={Muyao Niu and Xiaodong Cun and Xintao Wang and Yong Zhang and Ying Shan and Yinqiang Zheng},
      booktitle=ECCV,
      year={2024}
}